{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import librosa \n",
    "import sys\n",
    "import glob \n",
    "import random\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from tacotron.utils import get_spectrograms\n",
    "import pandas as pd\n",
    "import gc \n",
    "\n",
    "def read_speaker_info(speaker_info_path):\n",
    "    speaker_ids = []\n",
    "    with open(speaker_info_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            speaker_id = line.strip().split()[0]\n",
    "            speaker_ids.append(\"p\"+speaker_id)\n",
    "    return speaker_ids\n",
    "\n",
    "\n",
    "def read_filenames(root_dir):\n",
    "    speaker2filenames = defaultdict(lambda : [])\n",
    "    for path in sorted(glob.glob(os.path.join(root_dir, '*/*'))):\n",
    "        filename = path.strip().split('/')[-1]\n",
    "        speaker_id, utt_id = re.match(r'p(\\d+)_(\\d+)\\.wav', filename).groups()\n",
    "        speaker2filenames[\"p\"+speaker_id].append(path)\n",
    "    return speaker2filenames\n",
    "\n",
    "def wave_feature_extraction(wav_file, sr):\n",
    "    y, sr = librosa.load(wav_file, sr)\n",
    "    y, _ = librosa.effects.trim(y, top_db=20)\n",
    "    return y\n",
    "\n",
    "def spec_feature_extraction(wav_file):\n",
    "    mel, mag = get_spectrograms(wav_file)\n",
    "    return mel, mag\n",
    "\n",
    "\n",
    "def sample_single_segments(pickle_path,sample_path,segment_size,n_samples):\n",
    "\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # (utt_id, timestep, neg_utt_id, neg_timestep)\n",
    "    samples = []\n",
    "\n",
    "    # filter length > segment_size\n",
    "    utt_list = [key for key in data]\n",
    "    utt_list = sorted(list(filter(lambda u : len(data[u]) > segment_size, utt_list)))\n",
    "    print(f'{len(utt_list)} utterances')\n",
    "    sample_utt_index_list = random.choices(range(len(utt_list)), k=n_samples)\n",
    "\n",
    "    for i, utt_ind in enumerate(sample_utt_index_list):\n",
    "        if i % 500 == 0:\n",
    "            print(f'sample {i} samples')\n",
    "        utt_id = utt_list[utt_ind]\n",
    "        t = random.randint(0, len(data[utt_id]) - segment_size)\n",
    "        samples.append((utt_id, t))\n",
    "\n",
    "    with open(sample_path, 'w') as f:\n",
    "        json.dump(samples, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speaker_ids=read_speaker_info(\"/raid/users/ayesilkanat/MSC/VCTK/VCTK-Corpus/speaker-info.txt\")\n",
    "\n",
    "\n",
    "test_speaker_ids=[os.path.split(path)[-1] for path in sorted(glob.glob(\"/raid/users/ayesilkanat/MSC/SELL-CORPUS/dev/*/*\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage=0\n",
    "segment_size=128\n",
    "n_out_speakers=20\n",
    "test_prop=0.1\n",
    "sample_rate=24000\n",
    "training_samples=10000000\n",
    "testing_samples=10000\n",
    "n_utt_attr=5000\n",
    "\n",
    "\n",
    "output_dir = \"../spectrograms/sr_24000_mel_norm_128frame_256mel\"\n",
    "test_proportion = test_prop\n",
    "\n",
    "n_utts_attr = n_utt_attr\n",
    "\n",
    "#$raw_data_dir/wav48 $raw_data_dir/speaker-info.txt $data_dir $n_out_speakers $test_prop $sample_rate $n_utt_attr\n",
    "\n",
    "speaker2filenames = read_filenames(\"/raid/users/ayesilkanat/MSC/VCTK/VCTK-Corpus/wav48\")\n",
    "\n",
    "\n",
    "for folder_path in sorted(glob.glob(\"/raid/users/ayesilkanat/MSC/SELL-CORPUS/dev/*/*\")):\n",
    "    speaker_id=os.path.split(folder_path)[-1]\n",
    "    paths=glob.glob(os.path.join(folder_path,\"*.wav\"))\n",
    "    for path in paths:\n",
    "        speaker2filenames[speaker_id].append(path)\n",
    "\n",
    "        \n",
    "train_path_list, in_test_path_list, out_test_path_list = [], [], []\n",
    "for speaker in train_speaker_ids:\n",
    "    path_list = speaker2filenames[speaker]\n",
    "    random.shuffle(path_list)\n",
    "    test_data_size = int(len(path_list) * test_proportion)\n",
    "    train_path_list += path_list[:-test_data_size]\n",
    "    in_test_path_list += path_list[-test_data_size:]\n",
    "for speaker in test_speaker_ids:\n",
    "    path_list = speaker2filenames[speaker]\n",
    "    out_test_path_list += path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(os.path.join(output_dir, 'in_test_files.txt'), 'w') as f:\n",
    "    for path in in_test_path_list:\n",
    "        f.write(f'{path}\\n')\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(output_dir, 'out_test_files.txt'), 'w') as f:\n",
    "    for path in out_test_path_list:\n",
    "        f.write(f'{path}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train set, 39497 files\n",
      "processing 0 files\n",
      "processing 500 files\n",
      "processing 1000 files\n",
      "processing 1500 files\n",
      "processing 2000 files\n",
      "processing 2500 files\n",
      "processing 3000 files\n",
      "processing 3500 files\n",
      "processing 4000 files\n",
      "processing 4500 files\n",
      "processing 5000 files\n",
      "processing 5500 files\n",
      "processing 6000 files\n",
      "processing 6500 files\n",
      "processing 7000 files\n",
      "processing 7500 files\n",
      "processing 8000 files\n",
      "processing 8500 files\n",
      "processing 9000 files\n",
      "processing 9500 files\n",
      "processing 10000 files\n",
      "processing 10500 files\n",
      "processing 11000 files\n",
      "processing 11500 files\n",
      "processing 12000 files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-aac2a7a39ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'processing {i} files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_utts_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-686b5d9d48be>\u001b[0m in \u001b[0;36mspec_feature_extraction\u001b[0;34m(wav_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec_feature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spectrograms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MSC/adaptive-accent-conversion-SELL2VCTK/setup1/preprocess/tacotron/utils.py\u001b[0m in \u001b[0;36mget_spectrograms\u001b[0;34m(fpath)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# mel spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_mels, 1+n_fft//2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmag\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (n_mels, t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# to decibel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for dset, path_list in zip(['train', 'in_test', 'out_test'], \\\n",
    "        [train_path_list, in_test_path_list, out_test_path_list]):\n",
    "    print(f'processing {dset} set, {len(path_list)} files')\n",
    "    data = {}\n",
    "    output_path = os.path.join(output_dir, f'{dset}.pkl')\n",
    "    all_train_data = []\n",
    "    for i, path in enumerate(sorted(path_list)):\n",
    "        if i % 500 == 0 or i == len(path_list) - 1:\n",
    "            print(f'processing {i} files')\n",
    "        filename = path.strip().split('/')[-1]\n",
    "        mel, mag = spec_feature_extraction(path)\n",
    "        data[filename] = mel\n",
    "        if dset == 'train' and i < n_utts_attr:\n",
    "            all_train_data.append(mel)\n",
    "    if dset == 'train':\n",
    "        all_train_data = np.concatenate(all_train_data)\n",
    "        mean = np.mean(all_train_data, axis=0)\n",
    "        std = np.std(all_train_data, axis=0)\n",
    "        attr = {'mean': mean, 'std': std}\n",
    "        with open(os.path.join(output_dir, 'attr.pkl'), 'wb') as f:\n",
    "            pickle.dump(attr, f)\n",
    "    for key, val in data.items():\n",
    "        val = (val - mean) / std\n",
    "        data[key] = val\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/train.pkl\"\n",
    "output_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/train_\"+str(segment_size)+\".pkl\"\n",
    "\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "reduced_data = {key:val for key, val in data.items() if val.shape[0] > segment_size}\n",
    "\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(reduced_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reduced_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pickle_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/train.pkl\"\n",
    "sample_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/train_samples_\"+str(segment_size)+\".json\"\n",
    "n_samples = training_samples\n",
    "\n",
    "sample_single_segments(pickle_path,sample_path,segment_size,n_samples)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pickle_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/in_test.pkl\"\n",
    "sample_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/in_test_samples_\"+str(segment_size)+\".json\"\n",
    "n_samples = testing_samples\n",
    "\n",
    "sample_single_segments(pickle_path,sample_path,segment_size,n_samples)\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pickle_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/out_test.pkl\"\n",
    "sample_path = \"spectrograms/sr_24000_mel_norm_128frame_256mel/out_test_samples_\"+str(segment_size)+\".json\"\n",
    "n_samples = testing_samples\n",
    "sample_single_segments(pickle_path,sample_path,segment_size,n_samples)\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
